"""
Module de g√©n√©ration de r√©ponses (generation)
MVP1 : R√©pond aux questions en s'appuyant sur les √©v√©nements trouv√©s
Utilise Claude (Anthropic) pour la g√©n√©ration
"""

import os
from anthropic import Anthropic
from dotenv import load_dotenv

from retriever import search

# Charger les variables d'environnement
load_dotenv()


def build_prompt(query, retrieved_events):
    """
    Construit le prompt pour Mistral avec la question et les √©v√©nements.
    
    Args:
        query (str): Question de l'utilisateur
        retrieved_events (list): Liste des √©v√©nements pertinents
        
    Returns:
        str: Prompt format√©
    """
    # Construire le contexte avec les √©v√©nements
    context = "\n\n".join([
        f"√âv√©nement {event['rank']}:\n{event['text']}"
        for event in retrieved_events
    ])
    
    # Prompt syst√®me
    prompt = f"""Tu es un assistant sp√©cialis√© dans la recommandation d'√©v√©nements culturels √† Paris.

Voici les √©v√©nements pertinents pour r√©pondre √† la question de l'utilisateur :

{context}

Question de l'utilisateur : {query}

R√©ponds de mani√®re claire et concise en recommandant le ou les √©v√©nements les plus adapt√©s. Mentionne le titre, le lieu et la date."""
    
    return prompt


def generate_response(query, k=3):
    """
    G√©n√®re une r√©ponse compl√®te √† une question (RAG complet).
    
    Args:
        query (str): Question de l'utilisateur
        k (int): Nombre d'√©v√©nements √† r√©cup√©rer
        
    Returns:
        dict: R√©ponse avec le texte g√©n√©r√© et les sources
    """
    print(f"\nü§ñ G√©n√©ration de la r√©ponse pour : '{query}'")
    
    # 1. Retrieval : Chercher les √©v√©nements pertinents
    retrieved_events = search(query, k=k)
    
    # 2. Augmentation : Construire le prompt
    print("\nüìù Construction du prompt...")
    prompt = build_prompt(query, retrieved_events)
    
    # 3. Generation : Appeler Claude pour g√©n√©rer la r√©ponse
    print("üß† G√©n√©ration de la r√©ponse avec Claude...\n")
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        raise ValueError("‚ùå ANTHROPIC_API_KEY non trouv√©e")
    
    client = Anthropic(api_key=api_key)
    
    message = client.messages.create(
        model="claude-sonnet-4-5-20250929",
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": prompt
            }
        ]
    )
    
    answer = message.content[0].text
    
    return {
        "question": query,
        "answer": answer,
        "sources": retrieved_events
    }


if __name__ == "__main__":
    # Test du RAG complet
    print("=" * 70)
    print("üß™ TEST DU RAG COMPLET (Retrieval + Generation)")
    print("=" * 70)
    
    # Question test
    test_query = "Je cherche un concert de jazz √† Paris"
    
    # G√©n√©rer la r√©ponse
    result = generate_response(test_query, k=3)
    
    # Afficher la r√©ponse
    print("=" * 70)
    print("üí¨ R√âPONSE FINALE")
    print("=" * 70)
    print(f"\n‚ùì Question : {result['question']}\n")
    print(f"‚úÖ R√©ponse :\n{result['answer']}\n")
    print("=" * 70)
    print("üìö SOURCES UTILIS√âES")
    print("=" * 70)
    for source in result['sources']:
        print(f"\nüèÜ Rang {source['rank']} (Distance: {source['distance']:.4f})")
        print(source['text'][:100] + "...")
